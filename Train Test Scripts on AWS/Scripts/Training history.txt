[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 250531171174123879
, name: "/device:XLA_GPU:0"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 16711681866504620614
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_CPU:0"
device_type: "XLA_CPU"
memory_limit: 17179869184
locality {
}
incarnation: 9463294769346442540
physical_device_desc: "device: XLA_CPU device"
, name: "/device:GPU:0"
device_type: "GPU"
memory_limit: 11281491559
locality {
  bus_id: 1
  links {
  }
}
incarnation: 4564664637178207917
physical_device_desc: "device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7"
]

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, None, None, 3 0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, None, None, 6 1792        input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, None, None, 6 256         conv2d_1[0][0]                   
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, None, None, 6 36928       batch_normalization_1[0][0]      
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, None, None, 6 256         conv2d_2[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, None, None, 6 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, None, None, 1 73856       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, None, None, 1 512         conv2d_3[0][0]                   
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, None, None, 1 147584      batch_normalization_3[0][0]      
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, None, None, 1 512         conv2d_4[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, None, None, 1 0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, None, None, 2 295168      max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, None, None, 2 1024        conv2d_5[0][0]                   
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, None, None, 2 590080      batch_normalization_5[0][0]      
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, None, None, 2 1024        conv2d_6[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, None, None, 2 0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, None, None, 5 1180160     max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, None, None, 5 2048        conv2d_7[0][0]                   
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, None, None, 5 2359808     batch_normalization_7[0][0]      
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, None, None, 5 2048        conv2d_8[0][0]                   
__________________________________________________________________________________________________
up_sampling2d_1 (UpSampling2D)  (None, None, None, 5 0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, None, None, 7 0           batch_normalization_6[0][0]      
                                                                 up_sampling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, None, None, 2 1769728     concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, None, None, 2 1024        conv2d_9[0][0]                   
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, None, None, 2 590080      batch_normalization_9[0][0]      
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, None, None, 2 1024        conv2d_10[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_2 (UpSampling2D)  (None, None, None, 2 0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, None, None, 3 0           batch_normalization_4[0][0]      
                                                                 up_sampling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, None, None, 1 442496      concatenate_2[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, None, None, 1 512         conv2d_11[0][0]                  
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, None, None, 1 147584      batch_normalization_11[0][0]     
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, None, None, 1 512         conv2d_12[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_3 (UpSampling2D)  (None, None, None, 1 0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, None, None, 1 0           batch_normalization_2[0][0]      
                                                                 up_sampling2d_3[0][0]            
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, None, None, 6 110656      concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, None, None, 6 256         conv2d_13[0][0]                  
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, None, None, 6 36928       batch_normalization_13[0][0]     
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, None, None, 6 256         conv2d_14[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, None, None, 1 65          batch_normalization_14[0][0]     
==================================================================================================
Total params: 7,794,177
Trainable params: 7,788,545
Non-trainable params: 5,632
__________________________________________________________________________________________________


epoch: 	loss: 	val_loss: 	acc: 	val_acc: 
0	-0.0490594932553	-0.092974385852	
1	-0.109580789544	-0.0181195039116	
2	-0.310669401111	-0.0935872196523	
3	-0.420813754788	-0.0070016689389	
4	-0.434075763226	-0.385052686427	
5	-0.473162069768	-0.485116132796	
6	-0.514786051214	-0.407867740095	
7	-0.480207128618	-0.353150248565	
8	-0.493889614949	-0.13784423288	
9	-0.51311095424	-0.463479768634	
10	-0.520475762282	-0.478239690959	
11	-0.560640825424	-0.31187592566	
12	-0.542409670874	-0.40636634524	
13	-0.569726231098	-0.426338572558	
14	-0.536617707387	-0.439068324864	
15	-0.556133033065	-0.44723490268	
epoch: 	loss: 	val_loss: 
0	-0.256555187471	-0.173190531549	
1	-0.283119595104	-0.135953402817	
2	-0.231453758983	-0.217234139033	
3	-0.219034273532	-0.156475525307	
4	-0.233621059424	-0.112853250627	
5	-0.229751084869	-0.1997190229	
6	-0.283340514984	-0.260469884253	
7	-0.21588368994	-0.264934978451	
8	-0.180885923515	-0.254791745884	
9	-0.312400609357	-0.292939399628	
10	-0.202700549043	-0.19900563222	
11	-0.297593202662	-0.140908351725	
12	-0.269721498425	-0.23294196052	
13	-0.201943970438	-0.239635059945	
14	-0.310513518383	-0.478501087655	
15	-0.28192345367	-0.281136731827	
16	-0.256772930959	-0.225213812881	
17	-0.258031623375	-0.278043642002	
18	-0.314179377033	-0.383030778834	
19	-0.225412377089	-0.124362076682	
20	-0.291119712234	-0.0792639338357	
21	-0.238318210668	-0.373037442534	
22	-0.282442301557	-0.221598816505	
23	-0.285771789763	-0.304368518328	
24	-0.299861505561	-0.428041701099	
25	-0.225164136574	-0.400130324	
26	-0.231700300406	-0.21513997392	
27	-0.333135850354	-0.232521409956	
28	-0.255794418693	-0.313102457963	
29	-0.297730953666	-0.347470968148	
30	-0.334173741548	-0.0643689643216	
31	-0.321117454562	-0.443912229905	
32	-0.338702572651	-0.295062094416	
33	-0.323727466757	-0.367440014005	
34	-0.331636644243	-0.368659767796	
35	-0.290086922666	-0.382595899111	
36	-0.294532070321	-0.433292586667	
37	-0.339890594785	-0.328621184608	
38	-0.322463813708	-0.296299586046	
39	-0.286521464384	-0.332496776609	
40	-0.292116534513	-0.303232960127	
41	-0.346179044601	-0.495853682704	
42	-0.312127018362	-0.438367117468	
43	-0.305807174669	-0.335837305703	
44	-0.294281385764	-0.380707372547	
45	-0.282724288674	-0.373696342494	
46	-0.297146671094	-0.315169928986	
47	-0.37389324971	-0.46753047118	
48	-0.316217707333	-0.147027157032	
49	-0.276729231476	-0.422066391016	
50	-0.294713519703	-0.414172041133	
51	-0.289970851278	-0.29972037894	
52	-0.295638980354	-0.438560036328	
53	-0.318869992948	-0.362736298122	
54	-0.34170416957	-0.401191155942	
55	-0.296256822775	-0.387163520362	
56	-0.38270806207	-0.229293197878	
57	-0.290535807198	-0.387999032643	
58	-0.311649170056	-0.312837395751	
59	-0.327379185423	-0.407001823483	
60	-0.350239959997	-0.552464388371	
61	-0.293875008569	-0.345150011271	
62	-0.303816259536	-0.45218120381	
63	-0.299461317639	-0.216155479685	
64	-0.330788146032	-0.367323947223	
65	-0.279397194124	-0.4105943442	
66	-0.352972313209	-0.521001188827	
67	-0.297248107042	-0.358618832056	
68	-0.305241076431	-0.376962164933	
69	-0.287270633159	-0.346985434035	
70	-0.337295803279	-0.427222830083	
71	-0.326244028085	-0.412316203561	
72	-0.314320482818	-0.378318096586	
73	-0.331691957868	-0.36760072752	
74	-0.357012517703	-0.420557798201	
75	-0.283921993526	-0.477649350313	
76	-0.321746415226	-0.384907761663	
77	-0.297971552951	-0.323831446269	
78	-0.312681703645	-0.489860670177	
79	-0.363619352239	-0.345651191374	
80	-0.358231616733	-0.450667916861	
81	-0.292646870318	-0.376677639777	
82	-0.260763366999	-0.328237593828	
83	-0.321050669746	-0.283324616036	
84	-0.360044522005	-0.243663599086	
85	-0.307789856994	-0.332031389928	
86	-0.329731548539	-0.466537633596	
87	-0.306923316878	-0.425509520129	
88	-0.322511814849	-0.460777184285	
89	-0.387452525281	-0.362349199868	
90	-0.366525843269	-0.455195165636	
